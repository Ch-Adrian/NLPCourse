{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download three Polish models from the Huggingface repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline, AutoModel, AutoTokenizer, AutoModelForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FacebookAI/xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adrian/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at FacebookAI/xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe_roberta = pipeline(\"fill-mask\", model=\"FacebookAI/xlm-roberta-base\")\n",
    "pipe_roberta_settings = {\n",
    "    \"name\": \"pipe_roberta\",\n",
    "    \"type\": \"fill-mask\",\n",
    "    \"mask\": \"<mask>\",\n",
    "    \"data_type\": \"mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "pipe_roberta_classification = pipeline(\"zero-shot-classification\", model=\"FacebookAI/xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dkleczek/bert-base-polish-uncased-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dkleczek/bert-base-polish-uncased-v1 were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe_dkleczek = pipeline(\"fill-mask\", model=\"dkleczek/bert-base-polish-uncased-v1\")\n",
    "pipe_dkleczek_settings = {\n",
    "    \"name\": \"pipe_dkleczek\",\n",
    "    \"type\": \"fill-mask\",\n",
    "    \"mask\": \"[MASK]\",\n",
    "    \"data_type\": \"mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dkleczek/bert-base-polish-uncased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "pipe_dkleczek_classification = pipeline(\"zero-shot-classification\", model=\"dkleczek/bert-base-polish-uncased-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flax-community/papuGaPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_papuga = pipeline(\"text-generation\", model=\"flax-community/papuGaPT2\")\n",
    "pipe_papuga_settings = {\n",
    "    \"name\": \"pipe_papuga\",\n",
    "    \"type\": \"text-generation\",\n",
    "    \"mask\": \"\",\n",
    "    \"data_type\": \"without_mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at flax-community/papuGaPT2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "pipe_papuga_classification = pipeline(\"zero-shot-classification\", model=\"flax-community/papuGaPT2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### papluca/xlm-roberta-base-language-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_papluca = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")\n",
    "pipe_papluca_settings = {\n",
    "    \"name\": \"pipe_papluca\",\n",
    "    \"type\": \"text-classification\",\n",
    "    \"mask\": \"\",\n",
    "    \"data_type\": \"without_mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### google-bert/bert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-multilingual-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe_bert = pipeline(\"fill-mask\", model=\"google-bert/bert-base-multilingual-cased\")\n",
    "pipe_bert_settings = {\n",
    "    \"name\": \"pipe_bert\",\n",
    "    \"type\": \"fill-mask\",\n",
    "    \"mask\": \"[MASK]\",\n",
    "    \"data_type\": \"mask\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Failed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n"
     ]
    }
   ],
   "source": [
    "pipe_bert_classification = pipeline(\"zero-shot-classification\", model=\"google-bert/bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_fill_mask = [pipe_roberta, pipe_dkleczek,  pipe_bert]\n",
    "pipline_fill_mask_settings = [pipe_roberta_settings, pipe_dkleczek_settings, pipe_bert_settings]\n",
    "piplines_text_generation = [pipe_papuga]\n",
    "pipline_text_generation_settings = [pipe_papuga_settings]\n",
    "\n",
    "\n",
    "\n",
    "def run_pipelines_fill_mask(text):\n",
    "    print(\"----------------------------------------------\")\n",
    "    for sentence_idx in range(len(text[\"mask\"])):\n",
    "        for pipe, settings in zip(pipelines_fill_mask, pipline_fill_mask_settings):\n",
    "\n",
    "            print(f\"====== > Pipeline: {settings['name']} < ======\")\n",
    "            sentence = text['mask'][sentence_idx].replace(\"[MASK]\", pipe.tokenizer.mask_token)\n",
    "            print(f\"Text: {sentence}\")\n",
    "\n",
    "            preds = pipe(sentence, top_k=5)\n",
    "            preds2 = None\n",
    "            if settings[\"data_type\"] == \"mask\" and text['mask'][sentence_idx].count(\"[MASK]\") == 2:\n",
    "                preds2 = preds[1]\n",
    "                preds = preds[0]\n",
    "\n",
    "            for pred in preds:\n",
    "                print(f\"Score: {round(pred['score'], 3)}, predicted token: {pred['token_str']}.\")\n",
    "\n",
    "            if preds2:\n",
    "                print()\n",
    "                for pred in preds2:\n",
    "                    print(f\"Score: {round(pred['score'], 3)}, predicted token: {pred['token_str']}.\")\n",
    "            print()\n",
    "\n",
    "def run_pipeline_text_generation(text):\n",
    "    print(\"----------------------------------------------\")\n",
    "    for sentence_idx in range(len(text[\"mask\"])):\n",
    "        for pipe, settings in zip(piplines_text_generation, pipline_text_generation_settings):\n",
    "\n",
    "            print(f\"====== > Pipeline: {settings['name']} < ======\")\n",
    "            sentence = text['without_mask'][sentence_idx]\n",
    "            print(f\"Text: {sentence}\")\n",
    "\n",
    "            for _ in range(5):\n",
    "                preds = pipe(sentence, pad_token_id=50256, max_length=50)\n",
    "                print(f\"Generated text: {preds[0]['generated_text']}\")\n",
    "            print()\n",
    "\n",
    "\n",
    "def run_for_texts(texts, type='fill_mask'):\n",
    "    if type == 'fill_mask':\n",
    "        run_pipelines_fill_mask(texts)\n",
    "    else:\n",
    "        run_pipeline_text_generation(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise a method to test if the langage model understands Polish cases. E.g. testing for *nominal case* could be expressed as \"Warszawa to największe `[MASK]`\", and the masked word should be in nominative case. Create sentences for each case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_for_polish_cases = {\n",
    "    \"mask\": [\n",
    "        \"Warszawa to największe [MASK]\",\n",
    "        \"Pierogi to polskie [MASK]\",\n",
    "        \"Poznań jest sławny z dwóch [MASK]\",\n",
    "        \"Najwyższym szczytem w Polsce są [MASK]\",\n",
    "        \"Polska jest położona w [MASK]\"\n",
    "        ],\n",
    "    \"without_mask\": [\n",
    "        \"Warszawa to największe \",\n",
    "        \"Pierogi to polskie \",\n",
    "        \"Poznań jest sławny z dwóch \",\n",
    "        \"Najwyższym szczytem w Polsce są \",\n",
    "        \"Polska jest położona w \"\n",
    "        ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Warszawa to największe <mask>\n",
      "Score: 0.297, predicted token: ....\n",
      "Score: 0.165, predicted token: miasto.\n",
      "Score: 0.067, predicted token: !.\n",
      "Score: 0.054, predicted token: ....\n",
      "Score: 0.053, predicted token: city.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Warszawa to największe [MASK]\n",
      "Score: 0.668, predicted token: miasto.\n",
      "Score: 0.107, predicted token: ..\n",
      "Score: 0.03, predicted token: miejsce.\n",
      "Score: 0.021, predicted token: miasta.\n",
      "Score: 0.011, predicted token: pole.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Warszawa to największe [MASK]\n",
      "Score: 0.616, predicted token: ..\n",
      "Score: 0.164, predicted token: miasto.\n",
      "Score: 0.029, predicted token: Miasto.\n",
      "Score: 0.018, predicted token: miasta.\n",
      "Score: 0.013, predicted token: :.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Pierogi to polskie <mask>\n",
      "Score: 0.172, predicted token: !.\n",
      "Score: 0.162, predicted token: ..\n",
      "Score: 0.109, predicted token: ....\n",
      "Score: 0.056, predicted token: </s>.\n",
      "Score: 0.053, predicted token: ?.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Pierogi to polskie [MASK]\n",
      "Score: 0.422, predicted token: ..\n",
      "Score: 0.328, predicted token: ?.\n",
      "Score: 0.09, predicted token: !.\n",
      "Score: 0.02, predicted token: jedzenie.\n",
      "Score: 0.011, predicted token: danie.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Pierogi to polskie [MASK]\n",
      "Score: 0.469, predicted token: ..\n",
      "Score: 0.129, predicted token: :.\n",
      "Score: 0.031, predicted token: ;.\n",
      "Score: 0.02, predicted token: ,.\n",
      "Score: 0.014, predicted token: polskie.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Poznań jest sławny z dwóch <mask>\n",
      "Score: 0.738, predicted token: powodów.\n",
      "Score: 0.117, predicted token: stron.\n",
      "Score: 0.079, predicted token: przyczyn.\n",
      "Score: 0.009, predicted token: źródeł.\n",
      "Score: 0.006, predicted token: strony.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Poznań jest sławny z dwóch [MASK]\n",
      "Score: 0.555, predicted token: ..\n",
      "Score: 0.064, predicted token: stron.\n",
      "Score: 0.054, predicted token: :.\n",
      "Score: 0.027, predicted token: ?.\n",
      "Score: 0.026, predicted token: kategorii.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Poznań jest sławny z dwóch [MASK]\n",
      "Score: 0.487, predicted token: :.\n",
      "Score: 0.279, predicted token: ..\n",
      "Score: 0.017, predicted token: -.\n",
      "Score: 0.012, predicted token: ,.\n",
      "Score: 0.008, predicted token: miast.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Najwyższym szczytem w Polsce są <mask>\n",
      "Score: 0.711, predicted token: :.\n",
      "Score: 0.085, predicted token: ....\n",
      "Score: 0.021, predicted token: ....\n",
      "Score: 0.007, predicted token: :.\n",
      "Score: 0.006, predicted token: ..\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Najwyższym szczytem w Polsce są [MASK]\n",
      "Score: 0.958, predicted token: :.\n",
      "Score: 0.013, predicted token: ..\n",
      "Score: 0.002, predicted token: niemcy.\n",
      "Score: 0.001, predicted token: lasy.\n",
      "Score: 0.001, predicted token: ,.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Najwyższym szczytem w Polsce są [MASK]\n",
      "Score: 0.833, predicted token: :.\n",
      "Score: 0.073, predicted token: ..\n",
      "Score: 0.01, predicted token: na.\n",
      "Score: 0.007, predicted token: to.\n",
      "Score: 0.005, predicted token: następujące.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Polska jest położona w <mask>\n",
      "Score: 0.416, predicted token: :.\n",
      "Score: 0.096, predicted token: ....\n",
      "Score: 0.078, predicted token: ....\n",
      "Score: 0.054, predicted token: Warszawie.\n",
      "Score: 0.045, predicted token: Polsce.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Polska jest położona w [MASK]\n",
      "Score: 0.295, predicted token: polsce.\n",
      "Score: 0.048, predicted token: warszawie.\n",
      "Score: 0.048, predicted token: ..\n",
      "Score: 0.048, predicted token: europie.\n",
      "Score: 0.032, predicted token: niemczech.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Polska jest położona w [MASK]\n",
      "Score: 0.774, predicted token: ..\n",
      "Score: 0.13, predicted token: :.\n",
      "Score: 0.006, predicted token: granicach.\n",
      "Score: 0.003, predicted token: rejonie.\n",
      "Score: 0.003, predicted token: Polsce.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_polish_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Warszawa to największe \n",
      "Generated text: Warszawa to największe łęgowe zagłębie w Europie, gdzie znajdują się liczne rezerwaty, w tym rezerwaty przyrody, o bardzo ciekawej specyfice, ale i historii. Na obszarze Łęgów Narowistych żyje kilkadziesiąt gatunków pszczół, które do dziś stanowią\n",
      "Generated text: Warszawa to największe ród w okolicy. Co roku przyjeżdża tu kilka tysięcy zwiedzających, a to dopiero początek.\n",
      "Opuściwszy hotel na rogu ulic Raczyńskich i Kazimierza Wielkiego, dochodzimy do miejsca, gdzie niegdyś stała szkoła.\n",
      "Zatrzymujemy\n",
      "Generated text: Warszawa to największe ­powietrze w tej części świata. Jego obecność wśród polskich miast, które każdego roku zapełniają się ponad 2,5 mln turystów, to również odpowiedź na coraz częs...\n",
      "Od połowy XIX wieku, czyli po rewolucji przemysłowej\n",
      "Generated text: Warszawa to największe owiane złą sławą polskie miasto, w którym nie brak i turystów. Do zabytków nie brak, ale na zwiedzanie trzeba się dobrze przygotować. Podpowiadamy, jak wybrać się do Krakowa i co warto zwiedzić.\n",
      "Kraków słynie głównie\n",
      "Generated text: Warszawa to największe ­kraje południowo­wschodniej Unii Europejskiej. Na świecie, w porównaniu z krajami Europy Północnej, Polska jest siódmą najbardziej zaludnioną pod względem powierzchni rasą Afryki. To ogromny wzrost ludności Europy, która w ciągu ostatnich dwudziestu lat\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Pierogi to polskie \n",
      "Generated text: Pierogi to polskie owiane sławą tradycyjne potrawy, często ze starannie wyrabianą ręcznie tarcicą i smacznym nadzieniem. Można je jeść od wczesnej wiosny do późnej jesieni! Do ich przygotowania używa się mąki, sosów i przypraw\n",
      "Generated text: Pierogi to polskie čočeto, czyli pierogi z nadzieniem mięsnym. Ja osobiście uwielbiam pierogi z mięsem. Jednak najbardziej smakują mi te przygotowywane samodzielnie w domu, ale nie mam się do czego czepić.\n",
      "Ja do nadzie\n",
      "Generated text: Pierogi to polskie łemkie pierogi. Z racji tego, że w roku szkolnym już się skończyło, więc i ja musiałam zacząć je jeść. Jak się później okazało, były to zupełnie różne pierogi, różniące się głównie konsystencją. W jednym\n",
      "Generated text: Pierogi to polskie śćiecianie się tego, czy innego kraju. To jest też moje \"dziecko z obrazka\", a także moja \"ulubiona\" wersja z tej strony: http://www.mojamarzycielka.blogspot.\n",
      "Generated text: Pierogi to polskie ród, którego właściciele przez lata się utrzymywali, tworząc zręby państwowości. Tak do spółki z innymi rodami dziedzicznymi wytwarzały wyroby i ozdoby szlacheckie: szachy, gobeliny, obrazy, porcela\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Poznań jest sławny z dwóch \n",
      "Generated text: Poznań jest sławny z dwóch æwiczeń: pierwsze to æwiczenie sportowe, w którym zawodnik strzela co do milimetra, drugie – æwiczenie umysłowe.\n",
      "Na koniec warto także wspomnieć o æwiczeniach wytrzymałościowych\n",
      "Generated text: Poznań jest sławny z dwóch vessel’ów. Do jednej z nich należy słynny na całą Europę, jeden z tych dwóch to właśnie The Threat. Do tego The Threat należą to, iż jest ono nie tylko do nich, ale także\n",
      "Generated text: Poznań jest sławny z dwóch ��łłłłłłłłłłłłłńłłłłłłłłłłłłłłłłłłłłłłłłłłłł\n",
      "Generated text: Poznań jest sławny z dwóch nemezis: Aten i Rzymu) jest znany z trzech języków: grecki, grecoistyczny i arabski.\n",
      "Co ciekawe, wszystkie trzy mają te same korzenie. Pierwsze chrześcijaństwo w języku greckim\n",
      "Generated text: Poznań jest sławny z dwóch lian i z ich produkcji cukru rasowego. Jeden z nich został zastrzelony przez...\n",
      "Surowce, wyroby papiernicze, maszyny i narzędzia, papier, maszyny tokarskie, urządzenia, maszyny i urządzenia przemysłowe,\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Najwyższym szczytem w Polsce są \n",
      "Generated text: Najwyższym szczytem w Polsce są ál-do-do-dolary. W ramach tej waluty na świecie znajduje się ok. 4,5 mln ton ropy i 4,1 mln ton węgla. Rocznie wydobywamy z tych obiektów ok.\n",
      "Generated text: Najwyższym szczytem w Polsce są łęgi jesionowo-wiązowe, gdzie zachowały się tylko nieliczne egzemplarze, dlatego warto wspomnieć o rezerwacie Bukowate (Pruski) – największym z łęgów jesionowo-wiązowych, o\n",
      "Generated text: Najwyższym szczytem w Polsce są łów (1688 m), najwyższe pasmo górskie w Polsce (2200 m n.p.m) na całej szerokości pasma.\n",
      "Przełęcz pomiędzy Polską a Słowacją, nad którą położony jest Pilsko, uważana\n",
      "Generated text: Najwyższym szczytem w Polsce są ­Sucharskie Góry (Strzeliste Góry) po stronie słowackiej, leżącej około 60 kilometrów od Lwowa. To tam latem odbywają się zimowe i letnie wyjazdy po słowackiej stronie Tatr.\n",
      "Wyprawy\n",
      "Generated text: Najwyższym szczytem w Polsce są łęczyczanki, których najwyższe pasmo zajmuje 4786 metrów n.p.m. W Górach Świętokrzyskich jest jeszcze wiele mniejszych, a mianowicie Pico Veio i Opień.\n",
      "Wyspa w archipela\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Polska jest położona w \n",
      "Generated text: Polska jest położona w \u0001limanowskiej dzielnicy Zabierzów, w której do niedawna znajdowały się trzy hotele: 2,5-gwiazdkowy, trzynastoosobowy oraz jeden czterogwiazdkowy. Po tym, gdy na terenie tym powstał w 2012 r\n",
      "Generated text: Polska jest położona w owianym tajemnicą ajrackim i chronionym od wieków chrześcijaństwem (więcej na: www.angelik.pl), a jednak nie jesteśmy w stanie go kontrolować przez państwo, i do dzisiaj. W Europie ciągle panuje\n",
      "Generated text: Polska jest położona w lnie, a na nim po dwa lub trzy kamienie. W jednej z roślin można znaleźć na tym obszarze „złocie”. – Zakaz hodowli takich roślin w Polsce nie dotyczy tylko zwierząt domowych, także w handlu zwierzęcymi. W\n",
      "Generated text: Polska jest położona w ­krainie, gdzie w każdym miejscu panuje przyroda; tam też możemy obejrzeć wspaniałe zamki, kościoły z tysiącami krzyżyków na ścianach, wspaniałe zabytki przyrody. W Krainie Wielkich Jezior jest jedna z najlepszych restauracji, które w całym\n",
      "Generated text: Polska jest położona w *******. To samo miasto - Kraków i okoliczne miejscowosćy. Zaplanowałyscie podróż do Krakowa w celach rozrywkowych...\n",
      "Nie ma nic przyjemniejszego dla kobiety niż kobieta, która swoim wdziękiem wzbudza tak wiele\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_polish_cases, 'text_generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Devise a method to test long-range relationships such as gender. E.e. you can use two verbs with masculine and feminine gender, where one of the verbs is masked. Both verbs should have the same gender, assuming the subject is the same. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_for_gender = {\n",
    "    \"mask\": [\n",
    "        \"Poszedł do sklepu i kupił mleko. Czy [MASK] zapomniał o chlebie?\",\n",
    "        \"Alicja to bardzo miła dziewczyna. Lubię z [MASK] przybywać. [MASK] jest bardzo pomocna.\",\n",
    "        \"Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś [MASK] w klubie sportowym. [MASK] jest bardzo dobrym zawodnikiem.\",\n",
    "        \"Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię [MASK].\",\n",
    "        \"Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to [MASK] specjał.\"\n",
    "        ],\n",
    "    \"without_mask\": [\n",
    "        \"Poszedł do sklepu i kupił mleko. Czy chleb został przez \",\n",
    "        \"Alicja to bardzo miła dziewczyna. Przebywanie z \",\n",
    "        \"Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z \",\n",
    "        \"Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię \",\n",
    "        \"Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to \"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Poszedł do sklepu i kupił mleko. Czy <mask> zapomniał o chlebie?\n",
      "Score: 0.255, predicted token: nie.\n",
      "Score: 0.077, predicted token: ktoś.\n",
      "Score: 0.074, predicted token: m.\n",
      "Score: 0.062, predicted token: on.\n",
      "Score: 0.044, predicted token: ż.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Poszedł do sklepu i kupił mleko. Czy [MASK] zapomniał o chlebie?\n",
      "Score: 0.528, predicted token: on.\n",
      "Score: 0.078, predicted token: ktos.\n",
      "Score: 0.031, predicted token: pan.\n",
      "Score: 0.027, predicted token: moze.\n",
      "Score: 0.027, predicted token: nie.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Poszedł do sklepu i kupił mleko. Czy [MASK] zapomniał o chlebie?\n",
      "Score: 0.22, predicted token: się.\n",
      "Score: 0.092, predicted token: nie.\n",
      "Score: 0.042, predicted token: sam.\n",
      "Score: 0.021, predicted token: ten.\n",
      "Score: 0.021, predicted token: ,.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Alicja to bardzo miła dziewczyna. Lubię z <mask> przybywać. <mask> jest bardzo pomocna.\n",
      "Score: 0.972, predicted token: nią.\n",
      "Score: 0.014, predicted token: niej.\n",
      "Score: 0.005, predicted token: nimi.\n",
      "Score: 0.002, predicted token: nim.\n",
      "Score: 0.001, predicted token: ludźmi.\n",
      "\n",
      "Score: 0.477, predicted token: Zawsze.\n",
      "Score: 0.205, predicted token: Ona.\n",
      "Score: 0.028, predicted token: I.\n",
      "Score: 0.027, predicted token: Często.\n",
      "Score: 0.016, predicted token: Bardzo.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Alicja to bardzo miła dziewczyna. Lubię z [MASK] przybywać. [MASK] jest bardzo pomocna.\n",
      "Score: 0.859, predicted token: nia.\n",
      "Score: 0.039, predicted token: niej.\n",
      "Score: 0.024, predicted token: toba.\n",
      "Score: 0.017, predicted token: wami.\n",
      "Score: 0.017, predicted token: nimi.\n",
      "\n",
      "Score: 0.227, predicted token: i.\n",
      "Score: 0.166, predicted token: ona.\n",
      "Score: 0.112, predicted token: ale.\n",
      "Score: 0.106, predicted token: -.\n",
      "Score: 0.091, predicted token: alicja.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Alicja to bardzo miła dziewczyna. Lubię z [MASK] przybywać. [MASK] jest bardzo pomocna.\n",
      "Score: 0.154, predicted token: nią.\n",
      "Score: 0.072, predicted token: nim.\n",
      "Score: 0.066, predicted token: czasem.\n",
      "Score: 0.049, predicted token: tym.\n",
      "Score: 0.044, predicted token: niej.\n",
      "\n",
      "Score: 0.103, predicted token: Ale.\n",
      "Score: 0.045, predicted token: Ali.\n",
      "Score: 0.04, predicted token: Nie.\n",
      "Score: 0.026, predicted token: To.\n",
      "Score: 0.018, predicted token: Ma.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś <mask> w klubie sportowym. <mask> jest bardzo dobrym zawodnikiem.\n",
      "Score: 0.591, predicted token: pracował.\n",
      "Score: 0.348, predicted token: był.\n",
      "Score: 0.018, predicted token: gra.\n",
      "Score: 0.007, predicted token: stał.\n",
      "Score: 0.005, predicted token: został.\n",
      "\n",
      "Score: 0.225, predicted token: Marek.\n",
      "Score: 0.167, predicted token: Dziś.\n",
      "Score: 0.145, predicted token: Teraz.\n",
      "Score: 0.111, predicted token: Obecnie.\n",
      "Score: 0.081, predicted token: Dzisiaj.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś [MASK] w klubie sportowym. [MASK] jest bardzo dobrym zawodnikiem.\n",
      "Score: 0.44, predicted token: pracował.\n",
      "Score: 0.317, predicted token: grał.\n",
      "Score: 0.069, predicted token: był.\n",
      "Score: 0.033, predicted token: pracowałem.\n",
      "Score: 0.016, predicted token: byłem.\n",
      "\n",
      "Score: 0.36, predicted token: teraz.\n",
      "Score: 0.181, predicted token: marek.\n",
      "Score: 0.057, predicted token: obecnie.\n",
      "Score: 0.057, predicted token: i.\n",
      "Score: 0.051, predicted token: ale.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś [MASK] w klubie sportowym. [MASK] jest bardzo dobrym zawodnikiem.\n",
      "Score: 0.3, predicted token: grał.\n",
      "Score: 0.188, predicted token: był.\n",
      "Score: 0.127, predicted token: jest.\n",
      "Score: 0.032, predicted token: ma.\n",
      "Score: 0.029, predicted token: występował.\n",
      "\n",
      "Score: 0.877, predicted token: Marek.\n",
      "Score: 0.024, predicted token: Obecnie.\n",
      "Score: 0.007, predicted token: Nie.\n",
      "Score: 0.007, predicted token: ..\n",
      "Score: 0.005, predicted token: Ponadto.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię <mask>.\n",
      "Score: 0.025, predicted token: Michał.\n",
      "Score: 0.021, predicted token: Adam.\n",
      "Score: 0.018, predicted token: Piotr.\n",
      "Score: 0.018, predicted token: Łukasz.\n",
      "Score: 0.017, predicted token: Karol.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię [MASK].\n",
      "Score: 0.084, predicted token: chandler.\n",
      "Score: 0.079, predicted token: monika.\n",
      "Score: 0.057, predicted token: ross.\n",
      "Score: 0.022, predicted token: joey.\n",
      "Score: 0.018, predicted token: peter.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię [MASK].\n",
      "Score: 0.498, predicted token: Monika.\n",
      "Score: 0.011, predicted token: Marek.\n",
      "Score: 0.008, predicted token: Piotr.\n",
      "Score: 0.007, predicted token: K.\n",
      "Score: 0.005, predicted token: Michał.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to <mask> specjał.\n",
      "Score: 0.367, predicted token: jej.\n",
      "Score: 0.254, predicted token: prawdziwy.\n",
      "Score: 0.15, predicted token: mój.\n",
      "Score: 0.096, predicted token: nasz.\n",
      "Score: 0.03, predicted token: ich.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to [MASK] specjał.\n",
      "Score: 0.154, predicted token: jej.\n",
      "Score: 0.09, predicted token: nasz.\n",
      "Score: 0.064, predicted token: moj.\n",
      "Score: 0.046, predicted token: najlepszy.\n",
      "Score: 0.043, predicted token: prawdziwy.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to [MASK] specjał.\n",
      "Score: 0.388, predicted token: bardzo.\n",
      "Score: 0.049, predicted token: sam.\n",
      "Score: 0.035, predicted token: jeden.\n",
      "Score: 0.028, predicted token: wiele.\n",
      "Score: 0.026, predicted token: to.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Poszedł do sklepu i kupił mleko. Czy chleb został przez \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Poszedł do sklepu i kupił mleko. Czy chleb został przez owca rozkradziony? Czy był wypieczony w domu? Czy był przechowywany w lodowce? Ile zostało z obgotowanego chleba? I teraz nachodzi mnie pytanie:\n",
      "Czy\n",
      "Generated text: Poszedł do sklepu i kupił mleko. Czy chleb został przez owca zjedzony? Przecież wszyscy na to czekali!\n",
      "Nie. Poszedł do sklepu i nie trafił na „zabójczy” chleb. Poszedł do piekarni i wyszedł bez chleba\n",
      "Generated text: Poszedł do sklepu i kupił mleko. Czy chleb został przez owy brak mleka wyjęty? Nie ma problemu z tym chlewem. No cóż, chleb można kupić, a nie kupić.\n",
      "Przyjechał jakiś młody i powiedział, że za tydzień jest\n",
      "Generated text: Poszedł do sklepu i kupił mleko. Czy chleb został przez żone. Przecież musiał wrócić do domu! Zaczekał, aż wróci ze sklepu, potem kupił kanapkę i poszedł do kuchni. Okazało się, że mąż nie ma dzieci. Zro\n",
      "Generated text: Poszedł do sklepu i kupił mleko. Czy chleb został przez owy sklep odebrany? - pyta mężczyzna.\n",
      "- Nie, ponieważ był to wyrób spożywczy - odpowiada matka - to on go nie sprzedał. - Mówi się, że sprzedany za 1\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Alicja to bardzo miła dziewczyna. Przebywanie z \n",
      "Generated text: Alicja to bardzo miła dziewczyna. Przebywanie z laryngologiem to dla niej żaden problem w postaci zatkanych nokrzy.\n",
      "O czym może świadczyć zatkany nos i towarzysząca mu gorączka? Zwężenie ujścia nosa, duszno,\n",
      "Generated text: Alicja to bardzo miła dziewczyna. Przebywanie z owymi ludźmi, rozmowa i rozmowy też były przyjemnością :)\n",
      "Uśmiech i życzliwość oraz pozytywna atmosfera to bardzo ważna cecha. Jeśli ktoś szuka profesjonalnej pomocy w tym aspekcie to koniecznie powinna zapoznać się z\n",
      "Generated text: Alicja to bardzo miła dziewczyna. Przebywanie z owymi ludźmi ma zawsze jakieś plusy. Na pewno w przyszłości się na to zdecyduje.\n",
      "ja od pewnego czasu też mam jakieś dziwne pomysły w głowie, bo nie czuję się dobrze w kuchni:) ale\n",
      "Generated text: Alicja to bardzo miła dziewczyna. Przebywanie z jonami uważam za bardzo dobre przeżycie i polecam każdemu dziewczynom z ADHD, które chcą się uczyć bycia z dorosłymi.\n",
      "Anna to świetna kobieta, która w pełni odpowiada za prowadzenie zajęć\n",
      "Generated text: Alicja to bardzo miła dziewczyna. Przebywanie z owymi psami jest naprawdę przyjemne. Są bardzo otwarte. Polecam serdecznie.\n",
      "Jeśli szukasz dobrego psiaka dla swojego pupila, to musisz zwrócić uwagę na tą ofertę. Sprawdź sobie, może akurat w mieście\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z \n",
      "Generated text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z owianej złą sławą piłki nożnej. To jeden z niewielu polskich lekkoatletów z przeciętną formą. Ma za sobą epizody z reprezentacją piłki\n",
      "Generated text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z owianej złą sławą i niesłabnącą legendą sekcji piłki nożnej i piłkarskiej. Na każdym kroku podkreśla, że jest jednym z najlepszych piłkarzy\n",
      "Generated text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z \u0003zwartych chłopców. Bardzo go lubi. Gra w \"piłkę nożną\".\n",
      "Uwielbia piłkę nożną i uwielbia ją oglądać. Uwielbia też\n",
      "Generated text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z łeśowych zasad, co zaowocowało tym, że stał się piłkarzem ekstraklasy. W wieku 12 lat grał w Legii Warszawa grał w jednej z drużyn\n",
      "Generated text: Marek jest wielkim miłośnikiem piłki nożnej. Kiedyś był członkiem klubu sportowego. Bardzo dobry zawodnik wyrósł z łęczyńskiego podwórka.\n",
      "Jest ojcem dziesięciorga dzieci. On też kibicuje piłkarzom. – To jedna z najważniejszych osób w moim życiu.\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię \n",
      "Generated text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię nemezis. Drugi jest kocurek, kocurek po raz kolejny o imieniu kocur. Kocur w wieku około ośmiu miesięcy.\n",
      "Generated text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię ___ i waży 1100g, najmłodszy ma około 3 tygodnie. Jest dość ufna w stosunku do ludzi. Lubi wychodzić na podwórko\n",
      "Generated text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię owy.\n",
      "3. \"Nie bój się. Jestem kobietą. Moja siła. Kocham cię. Nie boję się mężczyzn takich jak ty. Kiedy ktoś\n",
      "Generated text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię owca, a pozostałe cztery to:\n",
      "W związku z wprowadzeniem systemu zarządzania jakością ISO 9001 w siedzibie biura spółki, w ostatnim czasie przeprowadzono szereg inwestycji mających\n",
      "Generated text: Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię _____ ma na imię___. Jest kocisko do oddania. Najmłodszy ma na imię ___ i ma 3 lata\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to \n",
      "Generated text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to ­bardzo dobre danie. Danie z kaszą i grzybami to bardzo dobra opcja na szybki obiad. Przygotowanie dania z kaszą jest\n",
      "Generated text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to owiana dobrymi wspomnieniami tradycja.\n",
      "Do garnka włożyliśmy śliwki, cebulę, pieczarki, obrane jabłka i cebulę, następnie\n",
      "Generated text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to owiana legendami i anegdotami historia kulinarna.\n",
      "Na blogu kulinarnym znajdziesz mnóstwo przepisów, które będą doskonałym uzupełnieniem Twoich\n",
      "Generated text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to owiane echem przez dzieciaki. I choć na pierwszy rzut oka wygląda zupełnie inaczej wydaje się bardzo podobne do swoich ulubionych, takich\n",
      "Generated text: Weronika lubi gotować. Ugotowała wiele dań w życiu. Wszystkie dania były bardzo smaczne. Danie z śliwkami to ­piecze z mojego przepisu. Pochwaliłam się nim na Instagramie, a ona opowiedziała co zobaczyła na moim talerzu.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_gender, type='text_generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the model captures real-world knolwedge. For instance a sentence \"`[MASK]` wrze w temperaturze 100 stopni, a zamarza w temperaturze 0 stopni Celsjusza.\" checks if the model \"knows\" the description of water. Define at least 3 such sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_for_real_world_knowledge = {\n",
    "    \"mask\": [\n",
    "        \"Woda wrze w temperaturze [MASK] stopni Celsjusza, a zamarza w temperaturze [MASK] stopni Celsjusza.\",\n",
    "        \"Stolicą Polski jest [MASK]\",\n",
    "        \"Grawitacja przyciąga nas [MASK] ziemi.\",\n",
    "        \"Trawa przeważnie ma kolor [MASK].\",\n",
    "        \"Ludzie mają [MASK] nogi.\"\n",
    "        ],\n",
    "    \"without_mask\": [\n",
    "        \"Ilość stopni Celcjusza, w których woda wrze wynosi \",\n",
    "        \"Ilość stopni Celcjusza, w których woda zamarza wynosi \",\n",
    "        \"Stolicą Polski jest \",\n",
    "        \"Grawitacja przyciąga nas w kierunku do \",\n",
    "        \"Trawa przeważnie ma kolor \",\n",
    "        \"Ilość nóg jaką mają ludzie to \"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Woda wrze w temperaturze <mask> stopni Celsjusza, a zamarza w temperaturze <mask> stopni Celsjusza.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.054, predicted token: 25.\n",
      "Score: 0.051, predicted token: 40.\n",
      "Score: 0.049, predicted token: 20.\n",
      "Score: 0.046, predicted token: 30.\n",
      "Score: 0.037, predicted token: 15.\n",
      "\n",
      "Score: 0.054, predicted token: 40.\n",
      "Score: 0.05, predicted token: 25.\n",
      "Score: 0.048, predicted token: 30.\n",
      "Score: 0.044, predicted token: 20.\n",
      "Score: 0.032, predicted token: 15.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Woda wrze w temperaturze [MASK] stopni Celsjusza, a zamarza w temperaturze [MASK] stopni Celsjusza.\n",
      "Score: 0.04, predicted token: 20.\n",
      "Score: 0.036, predicted token: 30.\n",
      "Score: 0.032, predicted token: 5.\n",
      "Score: 0.027, predicted token: 100.\n",
      "Score: 0.025, predicted token: 10.\n",
      "\n",
      "Score: 0.039, predicted token: 20.\n",
      "Score: 0.031, predicted token: 100.\n",
      "Score: 0.028, predicted token: 30.\n",
      "Score: 0.026, predicted token: 5.\n",
      "Score: 0.024, predicted token: 40.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Woda wrze w temperaturze [MASK] stopni Celsjusza, a zamarza w temperaturze [MASK] stopni Celsjusza.\n",
      "Score: 0.054, predicted token: 10.\n",
      "Score: 0.04, predicted token: 3.\n",
      "Score: 0.039, predicted token: 4.\n",
      "Score: 0.038, predicted token: 2.\n",
      "Score: 0.037, predicted token: 1.\n",
      "\n",
      "Score: 0.049, predicted token: 10.\n",
      "Score: 0.038, predicted token: 3.\n",
      "Score: 0.038, predicted token: 4.\n",
      "Score: 0.037, predicted token: 2.\n",
      "Score: 0.034, predicted token: 5.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Stolicą Polski jest <mask>\n",
      "Score: 0.207, predicted token: Polska.\n",
      "Score: 0.175, predicted token: ....\n",
      "Score: 0.059, predicted token: Warszawa.\n",
      "Score: 0.049, predicted token: ....\n",
      "Score: 0.048, predicted token: :.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Stolicą Polski jest [MASK]\n",
      "Score: 0.43, predicted token: :.\n",
      "Score: 0.289, predicted token: warszawa.\n",
      "Score: 0.029, predicted token: polska.\n",
      "Score: 0.027, predicted token: ..\n",
      "Score: 0.016, predicted token: miasto.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Stolicą Polski jest [MASK]\n",
      "Score: 0.636, predicted token: ..\n",
      "Score: 0.138, predicted token: :.\n",
      "Score: 0.065, predicted token: ....\n",
      "Score: 0.008, predicted token: to.\n",
      "Score: 0.006, predicted token: miasto.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Grawitacja przyciąga nas <mask> ziemi.\n",
      "Score: 0.639, predicted token: do.\n",
      "Score: 0.142, predicted token: z.\n",
      "Score: 0.081, predicted token: na.\n",
      "Score: 0.036, predicted token: wokół.\n",
      "Score: 0.019, predicted token: spod.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Grawitacja przyciąga nas [MASK] ziemi.\n",
      "Score: 0.908, predicted token: do.\n",
      "Score: 0.037, predicted token: od.\n",
      "Score: 0.022, predicted token: ku.\n",
      "Score: 0.016, predicted token: z.\n",
      "Score: 0.01, predicted token: na.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Grawitacja przyciąga nas [MASK] ziemi.\n",
      "Score: 0.126, predicted token: ##iona.\n",
      "Score: 0.111, predicted token: ##ion.\n",
      "Score: 0.097, predicted token: do.\n",
      "Score: 0.069, predicted token: ##z.\n",
      "Score: 0.052, predicted token: ##za.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Trawa przeważnie ma kolor <mask>.\n",
      "Score: 0.348, predicted token: zielony.\n",
      "Score: 0.232, predicted token: czerwony.\n",
      "Score: 0.148, predicted token: biały.\n",
      "Score: 0.119, predicted token: czarny.\n",
      "Score: 0.097, predicted token: niebieski.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Trawa przeważnie ma kolor [MASK].\n",
      "Score: 0.104, predicted token: skory.\n",
      "Score: 0.073, predicted token: zielony.\n",
      "Score: 0.062, predicted token: czerwony.\n",
      "Score: 0.043, predicted token: czarny.\n",
      "Score: 0.038, predicted token: ziemi.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Trawa przeważnie ma kolor [MASK].\n",
      "Score: 0.104, predicted token: brązowy.\n",
      "Score: 0.019, predicted token: mm.\n",
      "Score: 0.017, predicted token: r.\n",
      "Score: 0.016, predicted token: Orange.\n",
      "Score: 0.015, predicted token: K.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Ludzie mają <mask> nogi.\n",
      "Score: 0.207, predicted token: dwie.\n",
      "Score: 0.072, predicted token: cztery.\n",
      "Score: 0.07, predicted token: długie.\n",
      "Score: 0.058, predicted token: trzy.\n",
      "Score: 0.051, predicted token: dobre.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Ludzie mają [MASK] nogi.\n",
      "Score: 0.247, predicted token: słabe.\n",
      "Score: 0.054, predicted token: dwie.\n",
      "Score: 0.042, predicted token: długie.\n",
      "Score: 0.037, predicted token: połamane.\n",
      "Score: 0.031, predicted token: takie.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Ludzie mają [MASK] nogi.\n",
      "Score: 0.332, predicted token: 4.\n",
      "Score: 0.197, predicted token: 3.\n",
      "Score: 0.113, predicted token: 2.\n",
      "Score: 0.041, predicted token: duże.\n",
      "Score: 0.034, predicted token: cztery.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_real_world_knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Ilość stopni Celcjusza, w których woda wrze wynosi \n",
      "Generated text: Ilość stopni Celcjusza, w których woda wrze wynosi ...........0,1 [%]=0,02 [%]=0,0=0,005\n",
      "6.2.1. Odwodnienie terenu wokół budowy wodo\n",
      "Generated text: Ilość stopni Celcjusza, w których woda wrze wynosi ród Laclja, po którym się dziedziczy. Laclja w czasach Cezara miał być właśni, potym, który sam by się wyłamał w drodze w\n",
      "Generated text: Ilość stopni Celcjusza, w których woda wrze wynosi ˙ 1.5°C - tyle musi mieć głębokość, aby woda mogła być nawodniona i schłodzona. Nie można więc jej gotować, ale mo˙na je du�\n",
      "Generated text: Ilość stopni Celcjusza, w których woda wrze wynosi .................2°C, i jest w tym bardzo wysoka. Nie ma więc obaw o zalanie budynku. Jeśli natomiast zachodzi potrzeba, można w ten sposób osiągnąć pożądany efekt, który często pojawia\n",
      "Generated text: Ilość stopni Celcjusza, w których woda wrze wynosi ˆ30stopni Celsjusza. Pompa wodna musi być tak zbudowana, by bez trudu mogła ona być pompowana, w odróżnieniu od przepompowni wody, które mają średnicę mniejszą o 8\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Ilość stopni Celcjusza, w których woda zamarza wynosi \n",
      "Generated text: Ilość stopni Celcjusza, w których woda zamarza wynosi ˝¨ (2:18, 1:27, 15:27). W tym odcinku występuje także, jak i w innych o tej porze roku, woda ulewna, która\n",
      "Generated text: Ilość stopni Celcjusza, w których woda zamarza wynosi јe 0,50, zatem w roku, gdy nie było pokrywy śnieżnej.\n",
      "Pod warunkiem tego, że śnieg był w miejscu o małym zasoleniu, woda zamarzała\n",
      "Generated text: Ilość stopni Celcjusza, w których woda zamarza wynosi ˝. 10°C C. Woda zamarza z taką samą ilością soli fizjologicznej, jaką ma woda do spożycia. Woda ze źródeł geotermalnych i wody geotermalne nie\n",
      "Generated text: Ilość stopni Celcjusza, w których woda zamarza wynosi ........\n",
      "Stary Sącz to dawne centrum turystyczne z bogatą historią. Dziś już mało kto wyjeżdża stąd do Krynicy-Zdrój lub Krynicy-Zdrój. Są one idealnym miejscem dla amatorów wypoczynku nad\n",
      "Generated text: Ilość stopni Celcjusza, w których woda zamarza wynosi  6.\n",
      "Zapach: Nuty piżma oraz drzewnych nut korzennych pojawiają si podczas palenia w cygarach. W czasie palenia w cygarach, temperatura drewna waha si o\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Stolicą Polski jest \n",
      "Generated text: Stolicą Polski jest ród, który powstał w XIII wieku. W Warszawie istniała już ponad 3 tysiące lat temu, w Krakowie około 450, także w Lublinie około 10 tysięcy lat wcześniej, a w Krakowie ponad 7 tysięcy lat temu. Polska jest krajem\n",
      "Generated text: Stolicą Polski jest łęcz, ale trzeba nadmienić, że od dawna jesteśmy z niej dumni, zwłaszcza że w ostatnich latach znacznie się podniósł poziom życia i możliwości na rynku pracy. To wszystko w związku z tym, że nie ma tu miejsca na\n",
      "Generated text: Stolicą Polski jest 두의강동처이로 난요한 유고니다.\n",
      "Generated text: Stolicą Polski jest ród Piastów i jego siedziba. W wyniku podziału książęcy majątek uległ rozdzieleniu i zagarnięto dziedzictwo kultury materialnej i gospodarczej. W zamian za to od czasów Kazimierza Wielkiego i Piastów Piastów, w Polsce pozostał zamek na Wawe\n",
      "Generated text: Stolicą Polski jest owiana od tysiąca lat Polska. To kraj, do którego co roku przyjeżdża około pół miliona gości. Dla polskich katolików na całym świecie jest to bowiem jedno z ważniejszych miejsc pielgrzymkowych!\n",
      "Co zatem zrobić, by w Gnieźnie\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Grawitacja przyciąga nas w kierunku do \n",
      "Generated text: Grawitacja przyciąga nas w kierunku do rządzenia światem, a do władzy nad nim, którą sprawujemy. Jesteśmy władcami planet, bo przecież nie powinniśmy posiadać władzy nad tym, do czego dąży Ziemia w tej chwili. Jest to droga, którą wybieramy\n",
      "Generated text: Grawitacja przyciąga nas w kierunku do rządzenia i do sterowania ruchami naszego miasta, oraz do kształtowania jej granic. Każdy ma swoje własne sposoby, aby ją pokonać. Niestety nasza cywilizacja często zaczyna nas traktować przedmiotowo. Nasze drogi muszą być jak najkrótsze\n",
      "Generated text: Grawitacja przyciąga nas w kierunku do **** ***\n",
      "Doświadczenie to było jednym z ważniejszych fundamentów tego projektu, gdzie nie tylko byliśmy zainteresowani rozwojem naszej działalności, ale także naszym rozwojem i sukcesem.\n",
      "Od samego początku wiedzieliśmy, że chcemy z powrotem otworzyć\n",
      "Generated text: Grawitacja przyciąga nas w kierunku do rządzenia światem i nie ma w tym nic złego, jest jednak coś takiego, jak polityka. Nie da się jej nie zauważać i nie dostrzegać. Jeżeli ktoś z naszych rodaków chce się za wszelką cenę dowiedzieć o\n",
      "Generated text: Grawitacja przyciąga nas w kierunku do rządzenia, bowiem jesteśmy otoczeni nie tylko siłami, ale także inteligencją i rozsądkiem. Tak naprawdę nie interesuje nas, kto rządzi, lecz raczej jaka wartość w tym wszystkim jest na nasz sposób.\n",
      "W\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Trawa przeważnie ma kolor \n",
      "Generated text: Trawa przeważnie ma kolor écru. Zazwyczaj uprawiana w pojemnikach, na krzewach, jako obwódka, w donicach, jako ozdoba, na kwiat cięty i susz, w wazonie, a także w pojemnikach\n",
      "Generated text: Trawa przeważnie ma kolor łękowaty, ubarwiony przeważnie latkami, ale po rozwidleniu wygląda jeszcze bardziej okazale.\n",
      "Bylina. W zależności od fazy rozwoju, w której się znajduje, może przybierać różne barwy. Najbardziej wyrazi\n",
      "Generated text: Trawa przeważnie ma kolor łemkowy, dzięki czemu najlepiej wygląda w połączeniu z innym kolorem. Jeżeli chcemy zachować harmonię i naturalny kolor, warto wybierać odmiany w barwie bardziej pastelowej.\n",
      "Ważną rolę do prawidłowego koloryzowania pełni też rodzaj mebli,\n",
      "Generated text: Trawa przeważnie ma kolor łękowy, czasem bywa niebieskawa, czasem żółtozielona. Roślina ma bardzo zmienne upodobania: jeden woli łany, drugi łanu, zaś trzeci łanu może być czerwony (tak też nazywa swój gatunek trawę).\n",
      "Generated text: Trawa przeważnie ma kolor écru. Na takiej bazie można zrobić praktycznie dowolny wzorek. Można zrobić z niej motyla, anioła i serce. Wzory sercowe, sercowe w kropki, jak na zdjęciu poniżej, jak w przykładzie wyżej\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(texts_for_real_world_knowledge, type='text_generation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check zero-shot learning capabilites of the models. Provide at least 5 sentences with different sentiment for the following scheme: \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta ma jest zdecydowanie `[MASK]`\" Try different prompts, to see if they make any difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_with_sentiment = { \n",
    "    \"mask\": [\n",
    "        \"Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem [MASK].\",\n",
    "        \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie [MASK].\",\n",
    "        \"Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak [MASK].\",\n",
    "        \"Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie [MASK].\",\n",
    "        \"Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie [MASK].\",\n",
    "        \"Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie [MASK].\"\n",
    "        ],\n",
    "    \"without_mask\": [\n",
    "        \"Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem \",\n",
    "        \"'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie \",\n",
    "        \"Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak \",\n",
    "        \"Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie \",\n",
    "        \"Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie \",\n",
    "        \"Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie \"\n",
    "       ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem <mask>.\n",
      "Score: 0.523, predicted token: zadowolona.\n",
      "Score: 0.085, predicted token: super.\n",
      "Score: 0.082, predicted token: zadowolony.\n",
      "Score: 0.033, predicted token: fan.\n",
      "Score: 0.022, predicted token: bardzo.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem [MASK].\n",
      "Score: 0.023, predicted token: podekscytowana.\n",
      "Score: 0.023, predicted token: dumny.\n",
      "Score: 0.018, predicted token: gotowa.\n",
      "Score: 0.017, predicted token: zachwycona.\n",
      "Score: 0.015, predicted token: zaszczycony.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem [MASK].\n",
      "Score: 0.034, predicted token: pt.\n",
      "Score: 0.026, predicted token: piosenki.\n",
      "Score: 0.025, predicted token: ##em.\n",
      "Score: 0.023, predicted token: to.\n",
      "Score: 0.021, predicted token: ok.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie <mask>.\n",
      "Score: 0.197, predicted token: najlepsza.\n",
      "Score: 0.141, predicted token: dobra.\n",
      "Score: 0.038, predicted token: ważna.\n",
      "Score: 0.032, predicted token: moja.\n",
      "Score: 0.028, predicted token: piękna.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie [MASK].\n",
      "Score: 0.218, predicted token: lepsza.\n",
      "Score: 0.088, predicted token: dobra.\n",
      "Score: 0.064, predicted token: pozytywna.\n",
      "Score: 0.06, predicted token: najgorsza.\n",
      "Score: 0.048, predicted token: zła.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie [MASK].\n",
      "Score: 0.137, predicted token: słowa.\n",
      "Score: 0.062, predicted token: ta.\n",
      "Score: 0.047, predicted token: taka.\n",
      "Score: 0.031, predicted token: znana.\n",
      "Score: 0.029, predicted token: dobra.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak <mask>.\n",
      "Score: 0.204, predicted token: ty.\n",
      "Score: 0.171, predicted token: twoje.\n",
      "Score: 0.107, predicted token: Ty.\n",
      "Score: 0.05, predicted token: to.\n",
      "Score: 0.032, predicted token: :.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak [MASK].\n",
      "Score: 0.249, predicted token: ty.\n",
      "Score: 0.179, predicted token: ta.\n",
      "Score: 0.065, predicted token: ten.\n",
      "Score: 0.054, predicted token: te.\n",
      "Score: 0.047, predicted token: ja.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak [MASK].\n",
      "Score: 0.05, predicted token: słowa.\n",
      "Score: 0.039, predicted token: np.\n",
      "Score: 0.024, predicted token: ludzi.\n",
      "Score: 0.017, predicted token: zł.\n",
      "Score: 0.016, predicted token: w.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie <mask>.\n",
      "Score: 0.367, predicted token: proste.\n",
      "Score: 0.151, predicted token: trudne.\n",
      "Score: 0.074, predicted token: ....\n",
      "Score: 0.038, predicted token: życie.\n",
      "Score: 0.036, predicted token: ..\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie [MASK].\n",
      "Score: 0.11, predicted token: trudne.\n",
      "Score: 0.092, predicted token: dziwne.\n",
      "Score: 0.076, predicted token: smutne.\n",
      "Score: 0.068, predicted token: proste.\n",
      "Score: 0.066, predicted token: straszne.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie [MASK].\n",
      "Score: 0.113, predicted token: słowa.\n",
      "Score: 0.106, predicted token: ..\n",
      "Score: 0.056, predicted token: ,.\n",
      "Score: 0.037, predicted token: życie.\n",
      "Score: 0.031, predicted token: !.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie <mask>.\n",
      "Score: 0.343, predicted token: bardzo.\n",
      "Score: 0.18, predicted token: najbardziej.\n",
      "Score: 0.071, predicted token: ..\n",
      "Score: 0.04, predicted token: szczególnie.\n",
      "Score: 0.025, predicted token: mocno.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie [MASK].\n",
      "Score: 0.397, predicted token: strach.\n",
      "Score: 0.135, predicted token: paranoja.\n",
      "Score: 0.037, predicted token: dreszcz.\n",
      "Score: 0.034, predicted token: depresja.\n",
      "Score: 0.03, predicted token: to.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie [MASK].\n",
      "Score: 0.077, predicted token: ##w.\n",
      "Score: 0.053, predicted token: do.\n",
      "Score: 0.042, predicted token: więcej.\n",
      "Score: 0.041, predicted token: ##ż.\n",
      "Score: 0.039, predicted token: ##ś.\n",
      "\n",
      "====== > Pipeline: pipe_roberta < ======\n",
      "Text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie <mask>.\n",
      "Score: 0.317, predicted token: proste.\n",
      "Score: 0.158, predicted token: trudne.\n",
      "Score: 0.11, predicted token: blisko.\n",
      "Score: 0.077, predicted token: ważne.\n",
      "Score: 0.04, predicted token: możliwe.\n",
      "\n",
      "====== > Pipeline: pipe_dkleczek < ======\n",
      "Text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie [MASK].\n",
      "Score: 0.211, predicted token: dziwne.\n",
      "Score: 0.078, predicted token: niesamowite.\n",
      "Score: 0.077, predicted token: proste.\n",
      "Score: 0.069, predicted token: smutne.\n",
      "Score: 0.043, predicted token: straszne.\n",
      "\n",
      "====== > Pipeline: pipe_bert < ======\n",
      "Text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie [MASK].\n",
      "Score: 0.087, predicted token: wiele.\n",
      "Score: 0.069, predicted token: słowa.\n",
      "Score: 0.061, predicted token: samo.\n",
      "Score: 0.05, predicted token: co.\n",
      "Score: 0.043, predicted token: dobrze.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(text_with_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem \n",
      "Generated text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem owiana pogłoskami, że kiedyś i ja miałam taką nadzieję ;) Ale już nie długo:\n",
      "@Misiaaa: No i co to ma być? Ale i tak na pewno\n",
      "Generated text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem very familiarny.\n",
      "Jak dla mnie bardzo dobra impreza. Bardzo fajnie się bawiło a co najważniejsze było świetne nagłośnienie. Szkoda, że na taką imprezę trzeba czekać aż\n",
      "Generated text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem laryngologiem i wiem, że nie jestem \"za duża\" w stosunku do innych ludzi. Nie mam nic, co by mi przeszkadzało. W ogóle mnie to nie dotyka. Co do\n",
      "Generated text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem very many fail. To, co mi się podobało to to, że ludzie tańczyli i śpiewali. To niesamowite. To naprawdę super doświadczenie.Więcej\n",
      "Po ukończeniu szkoły\n",
      "Generated text: Ale ekstra występ! Podobały mi się te wszystkie piosenki. Jestem laryngologiem i mam kontakt z ludźmi. No i na pewno będę miała ochotę na dalszą karierę.\n",
      "Jak w większości przypadków, tak i tutaj będę mogła podzielić się spostrzeżeniami za pośrednictwem\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie \n",
      "Generated text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie ****. Nie mogę uwierzyć, że to był kiler. Nienawidzę tego filmu. '\n",
      "'Jestem załamany, bo wiem,\n",
      "Generated text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie owiana tajemnicą ze względu na to, że w filmie udział mają bracia Cavendishowie - były agent CIA i główny wróg Adolfa\n",
      "Generated text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie owiana tajemnicą.\n",
      "Uzupełniaj się w każdym odcinku i nie martw się - każdy nowy odcinek to nowe doświadczenie, a i też\n",
      "Generated text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie \u0003...\n",
      "W filmie tym John Lennon, Elm VanGel, Roy Henderson oraz Brad Stone prezentują dwa muzyczne\n",
      "Generated text: 'Ten film to był kiler. Nie mogłem się oderwać od ekranu.' Wypowiedź ta jest zdecydowanie owiana tajemnicą, a autorowi udało się ją wydobyć. Nie mogłem się doczekać tego filmu, bo uważam go za jeden z najlepszych w całym\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak \n",
      "Generated text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak łkanie i płacz, ale nie są\n",
      "Generated text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak owy brak, brak szacunku, lęk o\n",
      "Generated text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak łkanie, krzyk i jęki,\n",
      "Generated text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak ­– Bo tak jak ja tak i\n",
      "Generated text: Och nie! Nie! Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch! Muszę się uspokoić, ale jest we mnie pełno emocji takich jak ­– i o – i o–\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie \n",
      "Generated text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie łkanie, to jest strach - po prostu muszę odejść. - To jest przerażająca\n",
      "Generated text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie łkanie - pomyślał i nie rozumiał dlaczego tak bardzo się boi, ale nie podda\n",
      "Generated text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie łkające! To nie mogła go znieść. On... Ale, proszę mi wierzyć!\n",
      "Generated text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie ******** że mnie morduje... To jest to... Nie, dziękuję... Przepraszam. O\n",
      "Generated text: Dlaczego on musiał umrzeć? Dlaczego? Tak nie może być! Nie! Ja nie dam rady bez niego! Nie... Och muszę oddetchnąć. To jest takie łkanie i westchnienie. Nie mogę! Nie daję!\n",
      "- Ale... nie\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie \n",
      "Generated text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie łkanie nad swoim grzechem. Zawsze też w chwilach, w których o niej piszę – „nie mogłem w nią uwierzyć.”\n",
      "Generated text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie łkanie. Mam wiele wspomnień z dzieciństwa; takich jak spotkanie z Marią Sturbową w jej domu, kiedy\n",
      "Generated text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie ..........\n",
      "Kiedy usłyszałem, że po przeczytaniu książki na blogu o muzyce na świecie będzie to moje pierwsze spotkanie z nią to\n",
      "Generated text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie ..........\n",
      "Och, to ja... No tak, bo przecież nie wszyscy tak myślą. Myślę o mojej ukochanej pisar\n",
      "Generated text: Kiedyś przeczytałem pewną książkę. Często ją wspominam i lubię wracać do niej myślami. Zawsze kiedy ktoś o niej mówi to dopada mnie łkaniem i mam ochotę powiedzieć: „To tylko sen”. Jednak ta książka jest do kitu. Pokazuje, że nie\n",
      "\n",
      "====== > Pipeline: pipe_papuga < ======\n",
      "Text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie \n",
      "Generated text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie ródliwe! To jest dla mnie normalne! Wstyd! Nie chciałem tego. Czułem się tak, jak mój \n",
      "Generated text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie łkanie! A potem okazuje się, że nawet ten jeden rzut oka nie zrobił na mnie żadnego wrażenia.\n",
      "Ja również mam\n",
      "Generated text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie ­– z jednej strony, z drugiej z trzeciej. Miałem trzynaście lat i od małego wierzyłem w to, co ludzie\n",
      "Generated text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie *******! To tak jak nie masz pojęcia o tym jak funkcjonuje nasz świat. Jesteś tam! To twoja prawdziwa, niezalega\n",
      "Generated text: Jestem przegrywem! Przegrałem! Nie mogę uwierzyć! Jak to możliwe? Przecież byłem taki blisko! To jest takie rządzenie! Przegrałem! Nie mogłem tego przegrać! Jakbym wygrał! Z kimkolwiek wygraliście to co mi powiedzia\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_texts(text_with_sentiment, \"test_generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-shot-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines_zero_shot = [pipe_roberta_classification, pipe_dkleczek_classification, pipe_papuga_classification, pipe_bert_classification]\n",
    "\n",
    "labels_zero_shot_newspapers = [\"polityka\", \"sport\", \"muzyka\", \"film\", \"nauka\"]\n",
    "labels_zero_shot_emotions = [\"ekscytacja\", \"gniew\", \"smutek\", \"strach\", \"zaskoczenie\"]\n",
    "zero_shot_text_emotions = [\n",
    "    \"Ale jazda! Czuje się świetnie! Jestem pełen energii!\",\n",
    "    \"O Ty zdrajco! Jak mogłeś mi to zrobić? Nie daruję Ci tego!\",\n",
    "    \"Dlaczego musiał umrzeć? Dlaczego? To nie może być prawda! Nie!\",\n",
    "    \"Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch!\",\n",
    "    \"Och! Co to było? Nie mogę uwierzyć! To jest niesamowite!\"\n",
    "]\n",
    "\n",
    "zero_shot_text_newspaper = [\n",
    "    \"W sondażach widać, że partia rządząca traci poparcie. Wszystko przez łamanie prawa.\",\n",
    "    \"Lewandowski zdobył kolejną bramkę. Polska wygrywa!\",\n",
    "    \"Gitarzysta zagrał na gitarze koncert. Publiczność śpiewała razem z nim i była zachwycona.\",\n",
    "    \"Za tydzień odbędzie się premiera w kinach Gladiatora 2. Wszyscy fani poprzedniej części nie mogą się doczekać.\",\n",
    "    \"Nowa technologia została wynaleziona. Dzięki niej możliwe jest leczenie nowotworów\"\n",
    "]\n",
    "\n",
    "def run_pipelines_zero_shot(texts, labels):\n",
    "    print(\"----------------------------------------------\")\n",
    "    pipeline_dict = dict()\n",
    "    for sentence_idx in range(len(texts)):\n",
    "        for pipe in pipelines_zero_shot:\n",
    "\n",
    "            print(f\"====== > Pipeline: {pipe.model.config.name_or_path} < ======\")\n",
    "            pipe_name = str(pipe.model.config.name_or_path)\n",
    "            sentence = texts[sentence_idx]\n",
    "            print(f\"Text: {sentence}\")\n",
    "\n",
    "            preds = pipe(sentence, labels)\n",
    "            pred = preds[\"labels\"][0]\n",
    "            print(f\"Predicted label: {pred}.\")\n",
    "            if labels[sentence_idx] == pred:\n",
    "                if pipe_name in pipeline_dict:\n",
    "                    pipeline_dict[pipe_name] += 1\n",
    "                else: \n",
    "                    pipeline_dict[pipe_name] = 1\n",
    "            else:\n",
    "                if pipe_name in pipeline_dict:\n",
    "                    pipeline_dict[pipe_name] += 0\n",
    "                else: \n",
    "                    pipeline_dict[pipe_name] = 0\n",
    "            print()\n",
    "    \n",
    "    print(\"Predictions: \")\n",
    "    for key, value in pipeline_dict.items():\n",
    "        print(f\"Model: {key}, correct predictions: {value/len(texts)}\")\n",
    "    print(\"\")\n",
    "    print(flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Ale jazda! Czuje się świetnie! Jestem pełen energii!\n",
      "Predicted label: strach.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Ale jazda! Czuje się świetnie! Jestem pełen energii!\n",
      "Predicted label: zaskoczenie.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Ale jazda! Czuje się świetnie! Jestem pełen energii!\n",
      "Predicted label: ekscytacja.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Ale jazda! Czuje się świetnie! Jestem pełen energii!\n",
      "Predicted label: gniew.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: O Ty zdrajco! Jak mogłeś mi to zrobić? Nie daruję Ci tego!\n",
      "Predicted label: ekscytacja.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: O Ty zdrajco! Jak mogłeś mi to zrobić? Nie daruję Ci tego!\n",
      "Predicted label: ekscytacja.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: O Ty zdrajco! Jak mogłeś mi to zrobić? Nie daruję Ci tego!\n",
      "Predicted label: smutek.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: O Ty zdrajco! Jak mogłeś mi to zrobić? Nie daruję Ci tego!\n",
      "Predicted label: zaskoczenie.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Dlaczego musiał umrzeć? Dlaczego? To nie może być prawda! Nie!\n",
      "Predicted label: strach.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Dlaczego musiał umrzeć? Dlaczego? To nie może być prawda! Nie!\n",
      "Predicted label: ekscytacja.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Dlaczego musiał umrzeć? Dlaczego? To nie może być prawda! Nie!\n",
      "Predicted label: smutek.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Dlaczego musiał umrzeć? Dlaczego? To nie może być prawda! Nie!\n",
      "Predicted label: zaskoczenie.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch!\n",
      "Predicted label: strach.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch!\n",
      "Predicted label: ekscytacja.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch!\n",
      "Predicted label: smutek.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Uciekaj! Gonią nas! Nie mogą nas złapać! Słyszysz wiej! Ooch!\n",
      "Predicted label: zaskoczenie.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Och! Co to było? Nie mogę uwierzyć! To jest niesamowite!\n",
      "Predicted label: zaskoczenie.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Och! Co to było? Nie mogę uwierzyć! To jest niesamowite!\n",
      "Predicted label: gniew.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Och! Co to było? Nie mogę uwierzyć! To jest niesamowite!\n",
      "Predicted label: smutek.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Och! Co to było? Nie mogę uwierzyć! To jest niesamowite!\n",
      "Predicted label: smutek.\n",
      "\n",
      "Predictions: \n",
      "Model: FacebookAI/xlm-roberta-base, correct predictions: 0.4\n",
      "Model: dkleczek/bert-base-polish-uncased-v1, correct predictions: 0.0\n",
      "Model: flax-community/papuGaPT2, correct predictions: 0.4\n",
      "Model: google-bert/bert-base-multilingual-cased, correct predictions: 0.0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipelines_zero_shot(zero_shot_text_emotions, labels_zero_shot_emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: W sondażach widać, że partia rządząca traci poparcie. Wszystko przez łamanie prawa.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: W sondażach widać, że partia rządząca traci poparcie. Wszystko przez łamanie prawa.\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: W sondażach widać, że partia rządząca traci poparcie. Wszystko przez łamanie prawa.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: W sondażach widać, że partia rządząca traci poparcie. Wszystko przez łamanie prawa.\n",
      "Predicted label: polityka.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Lewandowski zdobył kolejną bramkę. Polska wygrywa!\n",
      "Predicted label: film.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Lewandowski zdobył kolejną bramkę. Polska wygrywa!\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Lewandowski zdobył kolejną bramkę. Polska wygrywa!\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Lewandowski zdobył kolejną bramkę. Polska wygrywa!\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Gitarzysta zagrał na gitarze koncert. Publiczność śpiewała razem z nim i była zachwycona.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Gitarzysta zagrał na gitarze koncert. Publiczność śpiewała razem z nim i była zachwycona.\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Gitarzysta zagrał na gitarze koncert. Publiczność śpiewała razem z nim i była zachwycona.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Gitarzysta zagrał na gitarze koncert. Publiczność śpiewała razem z nim i była zachwycona.\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Za tydzień odbędzie się premiera w kinach Gladiatora 2. Wszyscy fani poprzedniej części nie mogą się doczekać.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Za tydzień odbędzie się premiera w kinach Gladiatora 2. Wszyscy fani poprzedniej części nie mogą się doczekać.\n",
      "Predicted label: nauka.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Za tydzień odbędzie się premiera w kinach Gladiatora 2. Wszyscy fani poprzedniej części nie mogą się doczekać.\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Za tydzień odbędzie się premiera w kinach Gladiatora 2. Wszyscy fani poprzedniej części nie mogą się doczekać.\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: FacebookAI/xlm-roberta-base < ======\n",
      "Text: Nowa technologia została wynaleziona. Dzięki niej możliwe jest leczenie nowotworów\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: dkleczek/bert-base-polish-uncased-v1 < ======\n",
      "Text: Nowa technologia została wynaleziona. Dzięki niej możliwe jest leczenie nowotworów\n",
      "Predicted label: muzyka.\n",
      "\n",
      "====== > Pipeline: flax-community/papuGaPT2 < ======\n",
      "Text: Nowa technologia została wynaleziona. Dzięki niej możliwe jest leczenie nowotworów\n",
      "Predicted label: sport.\n",
      "\n",
      "====== > Pipeline: google-bert/bert-base-multilingual-cased < ======\n",
      "Text: Nowa technologia została wynaleziona. Dzięki niej możliwe jest leczenie nowotworów\n",
      "Predicted label: nauka.\n",
      "\n",
      "Predictions: \n",
      "Model: FacebookAI/xlm-roberta-base, correct predictions: 0.0\n",
      "Model: dkleczek/bert-base-polish-uncased-v1, correct predictions: 0.2\n",
      "Model: flax-community/papuGaPT2, correct predictions: 0.2\n",
      "Model: google-bert/bert-base-multilingual-cased, correct predictions: 0.6\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_pipelines_zero_shot(zero_shot_text_newspaper, labels_zero_shot_newspapers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer the following questions (2 points):\n",
    "\n",
    "* Which of the models produced the best results?\\\n",
    "    **After analysis, the best model appeared to be dkleczek/bert-base-polish-uncased-v1.\\\n",
    "        It returned the most logical results. Mostly they were not the expected ones, but still the most suitable**\\\n",
    "* Was any of the models able to capture Polish grammar?\\\n",
    "    **Based on results every model was able to\\\n",
    "        produce reasonable results grammatically correct. But sometimes the results were utterly wrong.\\\n",
    "        Completed with wrong words or with punctuation marks.\\\n",
    "        The model was learnt on a bunch of different texts and probably it just simply strived to fit words only by making a copy from other texts.\\\n",
    "        But it was not simple reckless copy, because it also tried to conform with previous sentences.\\\n",
    "        So model for sure doesn't know the grammar, but it only tries to adjust as good as it can.\\\n",
    "        It has a potential to give reasonable results, but this is always limited.**\n",
    "\n",
    "* Was any of the models able to capture long-distant relationships between the words?\\\n",
    "    **Yes, some of the models were able to derive context from previous sentences.\\\n",
    "        But there were models like pipe_bert or pipe_papuga which were significantly misleaded or lost.\\\n",
    "        For instance:\\\n",
    "        For pipe_bert:\\\n",
    "        In sentence: \"Monika lubi bawić się z kotkami. Posiada trzy kotki. Najstarszy kot ma na imię [MASK].\"\\\n",
    "        pipe_bert had the result: \"Score: 0.498, predicted token: Monika.\"\\\n",
    "        which means that this model has very little reasoning and named the cat with the same name which has the owner.\\\n",
    "        I don't think that this model seriously assumes that the cat has the same name. The model probably only copied name\\\n",
    "        from the previous sentence to the next without understanding in depth. So model tried to link together both sentences to\\\n",
    "        achieve cohesion, but without understanding.\\\n",
    "    \\\n",
    "        Also for pipe_papuga:\\\n",
    "        Text: \"Alicja to bardzo miła dziewczyna. Przebywanie z \"\\\n",
    "        Generated text: \"Alicja to bardzo miła dziewczyna. Przebywanie z laryngologiem to dla niej żaden problem w postaci zatkanych nokrzy.\\\n",
    "        O czym może świadczyć zatkany nos i towarzysząca mu gorączka? Zwężenie ujścia nosa, duszno,\"\\\n",
    "        This is first answer for the text and it looks like in last sentence model completely forgot the context of previous two.\\\n",
    "    \\\n",
    "        There were also models like pipe_dkleczek which had better results.**\n",
    "\n",
    "* Was any of the models able to capture world knowledge?\\\n",
    "    **It was a hard task for all models. Even pipe_dkleczek made mistakes. It looks more like models try to guess the answer and\\\n",
    "        mostly they fail. The model of test-generated type pipe_papuga had the worst results which didn't even fit reasonably.**\n",
    "\n",
    "* Was any of the models good at doing zero-shot classification?\\\n",
    "    **All models struggled to detect the correct label.\\\n",
    "    For example model FacebookAI/xlm-roberta-base was better at emotions, but\\\n",
    "    model google-bert/bert-base-multilingual-cased was better at guessing categories of texts.\\\n",
    "    These results weren't excellent, so overall this task is hard for these models.**\n",
    "\n",
    "* What are the most striking errors made by the models?\\\n",
    "    **The worst errors occurred during the prediction of numbers or when the model sometimes gave punctuation marks.\\\n",
    "        For text-generated model, there were also sentences generated that did not fit each other or with strange\n",
    "        words.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
